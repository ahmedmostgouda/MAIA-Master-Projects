{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"},"colab":{"name":"Train_all.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"h-z6gudl8S7q","colab_type":"text"},"source":["#CAD PROJECT\n","\n","Baseline model based on:\n","https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html#initialize-and-reshape-the-networks\n","\n","\n","Made by MAIA team: Jaime, Ahmed & \"Prem\""]},{"cell_type":"code","metadata":{"id":"Oo3jlid441fS","colab_type":"code","outputId":"5c8b227d-5ebd-4a78-fbe9-818c4572c640","executionInfo":{"status":"ok","timestamp":1578949745858,"user_tz":-60,"elapsed":2715,"user":{"displayName":"Jaime Simarro","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAaCDZo0qY0_I_MWZkHYpC_qNonaZr8W0nMUic4Aw=s64","userId":"03169857515179805755"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"S38EEinKyH26","colab_type":"text"},"source":["* In **finetuning**, we start with a pretrained model and update *all* of the model’s parameters for our new task, in essence retraining the whole model.\n","* In **feature extraction** we start with a pretrained model and only update the final layer weights from which we derive predictions. It is called feature extraction because we use the pretrained CNN as a fixed feature-extractor, and only change the output layer.\n","\n","In general both transfer learning methods follow the same few steps:\n","\n","-  Initialize the pretrained model\n","-  Reshape the final layer(s) to have the same number of outputs as the\n","   number of classes in the new dataset\n","-  Define for the optimization algorithm which parameters we want to\n","   update during training\n","-  Run the training step\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"MCZCXQHpyH27","colab_type":"code","outputId":"ac165c40-e6c5-40c3-83f9-bf4d29ed0409","executionInfo":{"status":"ok","timestamp":1578949749017,"user_tz":-60,"elapsed":5200,"user":{"displayName":"Jaime Simarro","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAaCDZo0qY0_I_MWZkHYpC_qNonaZr8W0nMUic4Aw=s64","userId":"03169857515179805755"}},"colab":{"base_uri":"https://localhost:8080/","height":69}},"source":["from __future__ import print_function \n","from __future__ import division\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import numpy as np\n","import torchvision\n","from torchvision import datasets, models, transforms\n","import matplotlib.pyplot as plt\n","import time\n","import random\n","import pandas as pd\n","import sys\n","import os\n","import copy\n","%matplotlib inline\n","\n","print(\"PyTorch Version: \",torch.__version__)\n","print(\"Torchvision Version: \",torchvision.__version__)\n","\n","!pip install barbar"],"execution_count":0,"outputs":[{"output_type":"stream","text":["PyTorch Version:  1.3.1\n","Torchvision Version:  0.4.2\n","Requirement already satisfied: barbar in /usr/local/lib/python3.6/dist-packages (0.2.1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"l21PQ7ATyH2q","colab_type":"code","colab":{}},"source":["path_folder='/content/drive/My Drive/Colab Notebooks/CAD Project/'\n","sys.path.insert(1, path_folder) # Import py files in the folder"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DZPcaNXsyH3D","colab_type":"text"},"source":["Inputs\n","------\n","\n","\n","The other inputs are as follows: ``num_classes`` is the number of\n","classes in the dataset, ``batch_size`` is the batch size used for\n","training and may be adjusted according to the capability of your\n","machine, ``num_epochs`` is the number of training epochs we want to run,\n","and ``feature_extract`` is a boolean that defines if we are finetuning\n","or feature extracting. If ``feature_extract = False``, the model is\n","finetuned and all model parameters are updated. If\n","``feature_extract = True``, only the last layer parameters are updated,\n","the others remain fixed.\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"nOaqhxcVyH3E","colab_type":"code","outputId":"99b9656e-ea79-469f-82b4-77e4393d963f","executionInfo":{"status":"ok","timestamp":1578956380538,"user_tz":-60,"elapsed":1473,"user":{"displayName":"Jaime Simarro","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAaCDZo0qY0_I_MWZkHYpC_qNonaZr8W0nMUic4Aw=s64","userId":"03169857515179805755"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["###### SELECT CHALLANGE TYPE ##########\n","\n","CHALLANGE_TYPE = {\n","    1: \"Dermo Challenge\",\n","    2: \"Histopathology Challenge\",\n","}\n","CHALLANGE_TYPE_INDEX = 2;\n","\n","CHALLANGE_TYPE_STR =CHALLANGE_TYPE.get(CHALLANGE_TYPE_INDEX, \"Invalid normalization type\")\n","print(CHALLANGE_TYPE_STR)\n","\n","###### CHANGE THIS PARAMETERS ###########\n","# Models to choose from [resnet, alexnet, vgg, squeezenet, densenet, inception]\n","MODEL_NAME = \"resnext50\"\n","LR=1e-4\n","# EXPERIMENT NAMES\n","EXPERIMENT_NAME='Train_complete'\n","SUB_EXPERIMENT_NAME = MODEL_NAME+str(LR)\n","\n","# Batch size for training (change depending on how much memory you have)\n","BATCH_SIZE = 32\n","\n","# Number of epochs to train for \n","NUM_EPOCHS = 16\n","\n","\n","PREPROCESS_DATA = False\n","AUGMENTATION_ENABLE = True\n","\n","if(CHALLANGE_TYPE_INDEX == 1):\n","  INPUT_SIZE=225\n","if(CHALLANGE_TYPE_INDEX == 2):\n","  INPUT_SIZE=96\n","\n","# Flag for feature extracting. When False, we finetune the whole model, \n","#   when True we only update the reshaped layer params\n","FEATURE_EXTRACT= False\n","USE_PRETRAINED = True\n","\n","\n","###### CHANGE THIS PARAMETERS ###########\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Histopathology Challenge\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"eWXB6FyxKqnl","colab_type":"code","colab":{}},"source":["options = {}\n","options['train_split']  = 0.2\n","options[\"input_size\"]=INPUT_SIZE\n","options[\"challenge_dir\"]=os.path.join(path_folder,CHALLANGE_TYPE_STR+\"/\")\n","if(PREPROCESS_DATA):\n","  options[\"train_dir\"]=os.path.join(options[\"challenge_dir\"],\"train_pre/\")\n","  options[\"val_dir\"]=os.path.join(options[\"challenge_dir\"],\"val_pre/\")\n","  options[\"test_dir\"]=os.path.join(options[\"challenge_dir\"],\"test_pre/\")\n","else:\n","  options[\"train_dir\"]=os.path.join(options[\"challenge_dir\"],\"train/\")\n","  options[\"val_dir\"]=os.path.join(options[\"challenge_dir\"],\"val/\")\n","  options[\"test_dir\"]=os.path.join(options[\"challenge_dir\"],\"test/\")\n","if(CHALLANGE_TYPE_INDEX == 1):\n","  options[\"experiments_dir\"]=os.path.join(path_folder,\"Dermo_Experiments\")\n","if(CHALLANGE_TYPE_INDEX == 2):\n","  options[\"experiments_dir\"]=os.path.join(path_folder,\"Histo_Experiments\")\n","options[\"models_dir\"]=os.path.join(options[\"experiments_dir\"],EXPERIMENT_NAME)\n","options[\"batch_size\"]=BATCH_SIZE\n","\n","# Number of classes in the dataset\n","num_classes = 2"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"C4FLswTfyH3X","colab_type":"text"},"source":["Initialize and Reshape the Networks\n","-----------------------------------\n","\n"]},{"cell_type":"code","metadata":{"id":"sdvqZT4j-cbT","colab_type":"code","colab":{}},"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import numpy as np\n","import torchvision\n","from torchvision import datasets, models, transforms\n","import matplotlib.pyplot as plt\n","import time\n","import random\n","import pandas as pd\n","import sys\n","import os\n","import copy\n","\n","def set_parameter_requires_grad(model, feature_extracting):\n","    \"\"\"\n","     \n","    This helper function sets the ``.requires_grad`` attribute of the\n","    parameters in the model to False when we are feature extracting. By\n","    default, when we load a pretrained model all of the parameters have\n","    ``.requires_grad=True``, which is fine if we are training from scratch\n","    or finetuning. However, if we are feature extracting and only want to\n","    compute gradients for the newly initialized layer then we want all of\n","    the other parameters to not require gradients. This will make more sense\n","    later.\n","    \"\"\"\n","    if feature_extracting:\n","        for param in model.parameters():\n","            param.requires_grad = False\n","            "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WXp8mtw298fl","colab_type":"code","outputId":"2f67400e-8905-489f-be99-a66b2b7d1728","executionInfo":{"status":"ok","timestamp":1578956387006,"user_tz":-60,"elapsed":7144,"user":{"displayName":"Jaime Simarro","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAaCDZo0qY0_I_MWZkHYpC_qNonaZr8W0nMUic4Aw=s64","userId":"03169857515179805755"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["from MAIA_model import initialize_model\n","# Initialize the model for this run\n","model_ft = initialize_model(MODEL_NAME, num_classes, FEATURE_EXTRACT, use_pretrained=USE_PRETRAINED)\n","\n","# Print the model we just instantiated\n","print(model_ft)\n","\n","model_ft.to('cuda')\n","\n","from torchsummary import summary\n","summary(model_ft, (3,INPUT_SIZE, INPUT_SIZE))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Downloading: \"https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth\" to /root/.cache/torch/checkpoints/resnext50_32x4d-7cdf4587.pth\n","100%|██████████| 95.8M/95.8M [00:02<00:00, 41.5MB/s]\n"],"name":"stderr"},{"output_type":"stream","text":["ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (3): Bottleneck(\n","      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (3): Bottleneck(\n","      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (4): Bottleneck(\n","      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (5): Bottleneck(\n","      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n","      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n","      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n","      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Linear(in_features=2048, out_features=2, bias=True)\n",")\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1           [-1, 64, 48, 48]           9,408\n","       BatchNorm2d-2           [-1, 64, 48, 48]             128\n","              ReLU-3           [-1, 64, 48, 48]               0\n","         MaxPool2d-4           [-1, 64, 24, 24]               0\n","            Conv2d-5          [-1, 128, 24, 24]           8,192\n","       BatchNorm2d-6          [-1, 128, 24, 24]             256\n","              ReLU-7          [-1, 128, 24, 24]               0\n","            Conv2d-8          [-1, 128, 24, 24]           4,608\n","       BatchNorm2d-9          [-1, 128, 24, 24]             256\n","             ReLU-10          [-1, 128, 24, 24]               0\n","           Conv2d-11          [-1, 256, 24, 24]          32,768\n","      BatchNorm2d-12          [-1, 256, 24, 24]             512\n","           Conv2d-13          [-1, 256, 24, 24]          16,384\n","      BatchNorm2d-14          [-1, 256, 24, 24]             512\n","             ReLU-15          [-1, 256, 24, 24]               0\n","       Bottleneck-16          [-1, 256, 24, 24]               0\n","           Conv2d-17          [-1, 128, 24, 24]          32,768\n","      BatchNorm2d-18          [-1, 128, 24, 24]             256\n","             ReLU-19          [-1, 128, 24, 24]               0\n","           Conv2d-20          [-1, 128, 24, 24]           4,608\n","      BatchNorm2d-21          [-1, 128, 24, 24]             256\n","             ReLU-22          [-1, 128, 24, 24]               0\n","           Conv2d-23          [-1, 256, 24, 24]          32,768\n","      BatchNorm2d-24          [-1, 256, 24, 24]             512\n","             ReLU-25          [-1, 256, 24, 24]               0\n","       Bottleneck-26          [-1, 256, 24, 24]               0\n","           Conv2d-27          [-1, 128, 24, 24]          32,768\n","      BatchNorm2d-28          [-1, 128, 24, 24]             256\n","             ReLU-29          [-1, 128, 24, 24]               0\n","           Conv2d-30          [-1, 128, 24, 24]           4,608\n","      BatchNorm2d-31          [-1, 128, 24, 24]             256\n","             ReLU-32          [-1, 128, 24, 24]               0\n","           Conv2d-33          [-1, 256, 24, 24]          32,768\n","      BatchNorm2d-34          [-1, 256, 24, 24]             512\n","             ReLU-35          [-1, 256, 24, 24]               0\n","       Bottleneck-36          [-1, 256, 24, 24]               0\n","           Conv2d-37          [-1, 256, 24, 24]          65,536\n","      BatchNorm2d-38          [-1, 256, 24, 24]             512\n","             ReLU-39          [-1, 256, 24, 24]               0\n","           Conv2d-40          [-1, 256, 12, 12]          18,432\n","      BatchNorm2d-41          [-1, 256, 12, 12]             512\n","             ReLU-42          [-1, 256, 12, 12]               0\n","           Conv2d-43          [-1, 512, 12, 12]         131,072\n","      BatchNorm2d-44          [-1, 512, 12, 12]           1,024\n","           Conv2d-45          [-1, 512, 12, 12]         131,072\n","      BatchNorm2d-46          [-1, 512, 12, 12]           1,024\n","             ReLU-47          [-1, 512, 12, 12]               0\n","       Bottleneck-48          [-1, 512, 12, 12]               0\n","           Conv2d-49          [-1, 256, 12, 12]         131,072\n","      BatchNorm2d-50          [-1, 256, 12, 12]             512\n","             ReLU-51          [-1, 256, 12, 12]               0\n","           Conv2d-52          [-1, 256, 12, 12]          18,432\n","      BatchNorm2d-53          [-1, 256, 12, 12]             512\n","             ReLU-54          [-1, 256, 12, 12]               0\n","           Conv2d-55          [-1, 512, 12, 12]         131,072\n","      BatchNorm2d-56          [-1, 512, 12, 12]           1,024\n","             ReLU-57          [-1, 512, 12, 12]               0\n","       Bottleneck-58          [-1, 512, 12, 12]               0\n","           Conv2d-59          [-1, 256, 12, 12]         131,072\n","      BatchNorm2d-60          [-1, 256, 12, 12]             512\n","             ReLU-61          [-1, 256, 12, 12]               0\n","           Conv2d-62          [-1, 256, 12, 12]          18,432\n","      BatchNorm2d-63          [-1, 256, 12, 12]             512\n","             ReLU-64          [-1, 256, 12, 12]               0\n","           Conv2d-65          [-1, 512, 12, 12]         131,072\n","      BatchNorm2d-66          [-1, 512, 12, 12]           1,024\n","             ReLU-67          [-1, 512, 12, 12]               0\n","       Bottleneck-68          [-1, 512, 12, 12]               0\n","           Conv2d-69          [-1, 256, 12, 12]         131,072\n","      BatchNorm2d-70          [-1, 256, 12, 12]             512\n","             ReLU-71          [-1, 256, 12, 12]               0\n","           Conv2d-72          [-1, 256, 12, 12]          18,432\n","      BatchNorm2d-73          [-1, 256, 12, 12]             512\n","             ReLU-74          [-1, 256, 12, 12]               0\n","           Conv2d-75          [-1, 512, 12, 12]         131,072\n","      BatchNorm2d-76          [-1, 512, 12, 12]           1,024\n","             ReLU-77          [-1, 512, 12, 12]               0\n","       Bottleneck-78          [-1, 512, 12, 12]               0\n","           Conv2d-79          [-1, 512, 12, 12]         262,144\n","      BatchNorm2d-80          [-1, 512, 12, 12]           1,024\n","             ReLU-81          [-1, 512, 12, 12]               0\n","           Conv2d-82            [-1, 512, 6, 6]          73,728\n","      BatchNorm2d-83            [-1, 512, 6, 6]           1,024\n","             ReLU-84            [-1, 512, 6, 6]               0\n","           Conv2d-85           [-1, 1024, 6, 6]         524,288\n","      BatchNorm2d-86           [-1, 1024, 6, 6]           2,048\n","           Conv2d-87           [-1, 1024, 6, 6]         524,288\n","      BatchNorm2d-88           [-1, 1024, 6, 6]           2,048\n","             ReLU-89           [-1, 1024, 6, 6]               0\n","       Bottleneck-90           [-1, 1024, 6, 6]               0\n","           Conv2d-91            [-1, 512, 6, 6]         524,288\n","      BatchNorm2d-92            [-1, 512, 6, 6]           1,024\n","             ReLU-93            [-1, 512, 6, 6]               0\n","           Conv2d-94            [-1, 512, 6, 6]          73,728\n","      BatchNorm2d-95            [-1, 512, 6, 6]           1,024\n","             ReLU-96            [-1, 512, 6, 6]               0\n","           Conv2d-97           [-1, 1024, 6, 6]         524,288\n","      BatchNorm2d-98           [-1, 1024, 6, 6]           2,048\n","             ReLU-99           [-1, 1024, 6, 6]               0\n","      Bottleneck-100           [-1, 1024, 6, 6]               0\n","          Conv2d-101            [-1, 512, 6, 6]         524,288\n","     BatchNorm2d-102            [-1, 512, 6, 6]           1,024\n","            ReLU-103            [-1, 512, 6, 6]               0\n","          Conv2d-104            [-1, 512, 6, 6]          73,728\n","     BatchNorm2d-105            [-1, 512, 6, 6]           1,024\n","            ReLU-106            [-1, 512, 6, 6]               0\n","          Conv2d-107           [-1, 1024, 6, 6]         524,288\n","     BatchNorm2d-108           [-1, 1024, 6, 6]           2,048\n","            ReLU-109           [-1, 1024, 6, 6]               0\n","      Bottleneck-110           [-1, 1024, 6, 6]               0\n","          Conv2d-111            [-1, 512, 6, 6]         524,288\n","     BatchNorm2d-112            [-1, 512, 6, 6]           1,024\n","            ReLU-113            [-1, 512, 6, 6]               0\n","          Conv2d-114            [-1, 512, 6, 6]          73,728\n","     BatchNorm2d-115            [-1, 512, 6, 6]           1,024\n","            ReLU-116            [-1, 512, 6, 6]               0\n","          Conv2d-117           [-1, 1024, 6, 6]         524,288\n","     BatchNorm2d-118           [-1, 1024, 6, 6]           2,048\n","            ReLU-119           [-1, 1024, 6, 6]               0\n","      Bottleneck-120           [-1, 1024, 6, 6]               0\n","          Conv2d-121            [-1, 512, 6, 6]         524,288\n","     BatchNorm2d-122            [-1, 512, 6, 6]           1,024\n","            ReLU-123            [-1, 512, 6, 6]               0\n","          Conv2d-124            [-1, 512, 6, 6]          73,728\n","     BatchNorm2d-125            [-1, 512, 6, 6]           1,024\n","            ReLU-126            [-1, 512, 6, 6]               0\n","          Conv2d-127           [-1, 1024, 6, 6]         524,288\n","     BatchNorm2d-128           [-1, 1024, 6, 6]           2,048\n","            ReLU-129           [-1, 1024, 6, 6]               0\n","      Bottleneck-130           [-1, 1024, 6, 6]               0\n","          Conv2d-131            [-1, 512, 6, 6]         524,288\n","     BatchNorm2d-132            [-1, 512, 6, 6]           1,024\n","            ReLU-133            [-1, 512, 6, 6]               0\n","          Conv2d-134            [-1, 512, 6, 6]          73,728\n","     BatchNorm2d-135            [-1, 512, 6, 6]           1,024\n","            ReLU-136            [-1, 512, 6, 6]               0\n","          Conv2d-137           [-1, 1024, 6, 6]         524,288\n","     BatchNorm2d-138           [-1, 1024, 6, 6]           2,048\n","            ReLU-139           [-1, 1024, 6, 6]               0\n","      Bottleneck-140           [-1, 1024, 6, 6]               0\n","          Conv2d-141           [-1, 1024, 6, 6]       1,048,576\n","     BatchNorm2d-142           [-1, 1024, 6, 6]           2,048\n","            ReLU-143           [-1, 1024, 6, 6]               0\n","          Conv2d-144           [-1, 1024, 3, 3]         294,912\n","     BatchNorm2d-145           [-1, 1024, 3, 3]           2,048\n","            ReLU-146           [-1, 1024, 3, 3]               0\n","          Conv2d-147           [-1, 2048, 3, 3]       2,097,152\n","     BatchNorm2d-148           [-1, 2048, 3, 3]           4,096\n","          Conv2d-149           [-1, 2048, 3, 3]       2,097,152\n","     BatchNorm2d-150           [-1, 2048, 3, 3]           4,096\n","            ReLU-151           [-1, 2048, 3, 3]               0\n","      Bottleneck-152           [-1, 2048, 3, 3]               0\n","          Conv2d-153           [-1, 1024, 3, 3]       2,097,152\n","     BatchNorm2d-154           [-1, 1024, 3, 3]           2,048\n","            ReLU-155           [-1, 1024, 3, 3]               0\n","          Conv2d-156           [-1, 1024, 3, 3]         294,912\n","     BatchNorm2d-157           [-1, 1024, 3, 3]           2,048\n","            ReLU-158           [-1, 1024, 3, 3]               0\n","          Conv2d-159           [-1, 2048, 3, 3]       2,097,152\n","     BatchNorm2d-160           [-1, 2048, 3, 3]           4,096\n","            ReLU-161           [-1, 2048, 3, 3]               0\n","      Bottleneck-162           [-1, 2048, 3, 3]               0\n","          Conv2d-163           [-1, 1024, 3, 3]       2,097,152\n","     BatchNorm2d-164           [-1, 1024, 3, 3]           2,048\n","            ReLU-165           [-1, 1024, 3, 3]               0\n","          Conv2d-166           [-1, 1024, 3, 3]         294,912\n","     BatchNorm2d-167           [-1, 1024, 3, 3]           2,048\n","            ReLU-168           [-1, 1024, 3, 3]               0\n","          Conv2d-169           [-1, 2048, 3, 3]       2,097,152\n","     BatchNorm2d-170           [-1, 2048, 3, 3]           4,096\n","            ReLU-171           [-1, 2048, 3, 3]               0\n","      Bottleneck-172           [-1, 2048, 3, 3]               0\n","AdaptiveAvgPool2d-173           [-1, 2048, 1, 1]               0\n","          Linear-174                    [-1, 2]           4,098\n","================================================================\n","Total params: 22,984,002\n","Trainable params: 22,984,002\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.11\n","Forward/backward pass size (MB): 66.46\n","Params size (MB): 87.68\n","Estimated Total Size (MB): 154.24\n","----------------------------------------------------------------\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"7drWDjuZyH3g","colab_type":"text"},"source":["Load Data\n","---------\n","\n","Now that we know what the input size must be, we can initialize the data\n","transforms, image datasets, and the dataloaders. Notice, the models were\n","pretrained with the hard-coded normalization values, as described\n","`here <https://pytorch.org/docs/master/torchvision/models.html>`__.\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"bkPHyqlghgQO","colab_type":"code","outputId":"52c75cb9-10ba-4bab-91a7-ea4625145e22","executionInfo":{"status":"ok","timestamp":1578956387258,"user_tz":-60,"elapsed":7154,"user":{"displayName":"Jaime Simarro","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAaCDZo0qY0_I_MWZkHYpC_qNonaZr8W0nMUic4Aw=s64","userId":"03169857515179805755"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from MAIA_Loader import get_train_valid_loader_AUG, get_val_loader,get_train_loader_AUG\n","\n","data_loader_train=get_train_loader_AUG(data_dir=options[\"train_dir\"],batch_size= options[\"batch_size\"],augment=AUGMENTATION_ENABLE, input_size= options[\"input_size\"],challenge_type=CHALLANGE_TYPE_INDEX)\n","data_loader_val=get_train_loader_AUG(data_dir=options[\"val_dir\"],batch_size= options[\"batch_size\"],augment=AUGMENTATION_ENABLE, input_size= options[\"input_size\"],challenge_type=CHALLANGE_TYPE_INDEX)\n","\n","dataset_complete_train=torch.utils.data.ConcatDataset((data_loader_train.dataset,data_loader_val.dataset))\n","\n","\n","dataloader_complete_train = torch.utils.data.DataLoader(\n","    dataset_complete_train, batch_size=options[\"batch_size\"], shuffle=True)\n","\n","len(dataloader_complete_train.dataset)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["29494"]},"metadata":{"tags":[]},"execution_count":37}]},{"cell_type":"markdown","metadata":{"id":"sqJagrKuyH3l","colab_type":"text"},"source":["Create the Optimizer\n","--------------------\n","\n","Now that the model structure is correct, the final step for finetuning\n","and feature extracting is to create an optimizer that only updates the\n","desired parameters. Recall that after loading the pretrained model, but\n","before reshaping, if ``feature_extract=True`` we manually set all of the\n","parameter’s ``.requires_grad`` attributes to False. Then the\n","reinitialized layer’s parameters have ``.requires_grad=True`` by\n","default. So now we know that *all parameters that have\n",".requires_grad=True should be optimized.* Next, we make a list of such\n","parameters and input this list to the ADAM algorithm constructor.\n","\n","To verify this, check out the printed parameters to learn. When\n","finetuning, this list should be long and include all of the model\n","parameters. However, when feature extracting this list should be short\n","and only include the weights and biases of the reshaped layers.\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"XDJOVdXkyH3n","colab_type":"code","outputId":"5f09c998-0a5e-4c3a-da9b-067b3bd5c76b","executionInfo":{"status":"ok","timestamp":1578956387670,"user_tz":-60,"elapsed":7266,"user":{"displayName":"Jaime Simarro","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAaCDZo0qY0_I_MWZkHYpC_qNonaZr8W0nMUic4Aw=s64","userId":"03169857515179805755"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# Detect if we have a GPU available\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","# Send the model to GPU\n","model_ft = model_ft.to(device)\n","\n","# Gather the parameters to be optimized/updated in this run. If we are\n","#  finetuning we will be updating all parameters. However, if we are \n","#  doing feature extract method, we will only update the parameters\n","#  that we have just initialized, i.e. the parameters with requires_grad\n","#  is True.\n","params_to_update = model_ft.parameters()\n","print(\"Params to learn:\")\n","if FEATURE_EXTRACT:\n","    params_to_update = []\n","    for name,param in model_ft.named_parameters():\n","        if param.requires_grad == True:\n","            params_to_update.append(param)\n","            print(\"\\t\",name)\n","else:\n","    for name,param in model_ft.named_parameters():\n","        if param.requires_grad == True:\n","            print(\"\\t\",name)\n","\n","# Observe that all parameters are being optimized\n","optimizer_ft = optim.Adam(params_to_update, lr=LR)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Params to learn:\n","\t conv1.weight\n","\t bn1.weight\n","\t bn1.bias\n","\t layer1.0.conv1.weight\n","\t layer1.0.bn1.weight\n","\t layer1.0.bn1.bias\n","\t layer1.0.conv2.weight\n","\t layer1.0.bn2.weight\n","\t layer1.0.bn2.bias\n","\t layer1.0.conv3.weight\n","\t layer1.0.bn3.weight\n","\t layer1.0.bn3.bias\n","\t layer1.0.downsample.0.weight\n","\t layer1.0.downsample.1.weight\n","\t layer1.0.downsample.1.bias\n","\t layer1.1.conv1.weight\n","\t layer1.1.bn1.weight\n","\t layer1.1.bn1.bias\n","\t layer1.1.conv2.weight\n","\t layer1.1.bn2.weight\n","\t layer1.1.bn2.bias\n","\t layer1.1.conv3.weight\n","\t layer1.1.bn3.weight\n","\t layer1.1.bn3.bias\n","\t layer1.2.conv1.weight\n","\t layer1.2.bn1.weight\n","\t layer1.2.bn1.bias\n","\t layer1.2.conv2.weight\n","\t layer1.2.bn2.weight\n","\t layer1.2.bn2.bias\n","\t layer1.2.conv3.weight\n","\t layer1.2.bn3.weight\n","\t layer1.2.bn3.bias\n","\t layer2.0.conv1.weight\n","\t layer2.0.bn1.weight\n","\t layer2.0.bn1.bias\n","\t layer2.0.conv2.weight\n","\t layer2.0.bn2.weight\n","\t layer2.0.bn2.bias\n","\t layer2.0.conv3.weight\n","\t layer2.0.bn3.weight\n","\t layer2.0.bn3.bias\n","\t layer2.0.downsample.0.weight\n","\t layer2.0.downsample.1.weight\n","\t layer2.0.downsample.1.bias\n","\t layer2.1.conv1.weight\n","\t layer2.1.bn1.weight\n","\t layer2.1.bn1.bias\n","\t layer2.1.conv2.weight\n","\t layer2.1.bn2.weight\n","\t layer2.1.bn2.bias\n","\t layer2.1.conv3.weight\n","\t layer2.1.bn3.weight\n","\t layer2.1.bn3.bias\n","\t layer2.2.conv1.weight\n","\t layer2.2.bn1.weight\n","\t layer2.2.bn1.bias\n","\t layer2.2.conv2.weight\n","\t layer2.2.bn2.weight\n","\t layer2.2.bn2.bias\n","\t layer2.2.conv3.weight\n","\t layer2.2.bn3.weight\n","\t layer2.2.bn3.bias\n","\t layer2.3.conv1.weight\n","\t layer2.3.bn1.weight\n","\t layer2.3.bn1.bias\n","\t layer2.3.conv2.weight\n","\t layer2.3.bn2.weight\n","\t layer2.3.bn2.bias\n","\t layer2.3.conv3.weight\n","\t layer2.3.bn3.weight\n","\t layer2.3.bn3.bias\n","\t layer3.0.conv1.weight\n","\t layer3.0.bn1.weight\n","\t layer3.0.bn1.bias\n","\t layer3.0.conv2.weight\n","\t layer3.0.bn2.weight\n","\t layer3.0.bn2.bias\n","\t layer3.0.conv3.weight\n","\t layer3.0.bn3.weight\n","\t layer3.0.bn3.bias\n","\t layer3.0.downsample.0.weight\n","\t layer3.0.downsample.1.weight\n","\t layer3.0.downsample.1.bias\n","\t layer3.1.conv1.weight\n","\t layer3.1.bn1.weight\n","\t layer3.1.bn1.bias\n","\t layer3.1.conv2.weight\n","\t layer3.1.bn2.weight\n","\t layer3.1.bn2.bias\n","\t layer3.1.conv3.weight\n","\t layer3.1.bn3.weight\n","\t layer3.1.bn3.bias\n","\t layer3.2.conv1.weight\n","\t layer3.2.bn1.weight\n","\t layer3.2.bn1.bias\n","\t layer3.2.conv2.weight\n","\t layer3.2.bn2.weight\n","\t layer3.2.bn2.bias\n","\t layer3.2.conv3.weight\n","\t layer3.2.bn3.weight\n","\t layer3.2.bn3.bias\n","\t layer3.3.conv1.weight\n","\t layer3.3.bn1.weight\n","\t layer3.3.bn1.bias\n","\t layer3.3.conv2.weight\n","\t layer3.3.bn2.weight\n","\t layer3.3.bn2.bias\n","\t layer3.3.conv3.weight\n","\t layer3.3.bn3.weight\n","\t layer3.3.bn3.bias\n","\t layer3.4.conv1.weight\n","\t layer3.4.bn1.weight\n","\t layer3.4.bn1.bias\n","\t layer3.4.conv2.weight\n","\t layer3.4.bn2.weight\n","\t layer3.4.bn2.bias\n","\t layer3.4.conv3.weight\n","\t layer3.4.bn3.weight\n","\t layer3.4.bn3.bias\n","\t layer3.5.conv1.weight\n","\t layer3.5.bn1.weight\n","\t layer3.5.bn1.bias\n","\t layer3.5.conv2.weight\n","\t layer3.5.bn2.weight\n","\t layer3.5.bn2.bias\n","\t layer3.5.conv3.weight\n","\t layer3.5.bn3.weight\n","\t layer3.5.bn3.bias\n","\t layer4.0.conv1.weight\n","\t layer4.0.bn1.weight\n","\t layer4.0.bn1.bias\n","\t layer4.0.conv2.weight\n","\t layer4.0.bn2.weight\n","\t layer4.0.bn2.bias\n","\t layer4.0.conv3.weight\n","\t layer4.0.bn3.weight\n","\t layer4.0.bn3.bias\n","\t layer4.0.downsample.0.weight\n","\t layer4.0.downsample.1.weight\n","\t layer4.0.downsample.1.bias\n","\t layer4.1.conv1.weight\n","\t layer4.1.bn1.weight\n","\t layer4.1.bn1.bias\n","\t layer4.1.conv2.weight\n","\t layer4.1.bn2.weight\n","\t layer4.1.bn2.bias\n","\t layer4.1.conv3.weight\n","\t layer4.1.bn3.weight\n","\t layer4.1.bn3.bias\n","\t layer4.2.conv1.weight\n","\t layer4.2.bn1.weight\n","\t layer4.2.bn1.bias\n","\t layer4.2.conv2.weight\n","\t layer4.2.bn2.weight\n","\t layer4.2.bn2.bias\n","\t layer4.2.conv3.weight\n","\t layer4.2.bn3.weight\n","\t layer4.2.bn3.bias\n","\t fc.weight\n","\t fc.bias\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"eTUD-FuYyH3s","colab_type":"text"},"source":["Train the model\n","--------------------------------\n","\n","The next step is to setup the loss for the model, then run the\n","training and validation function for the set number of epochs. Notice,\n","depending on the number of epochs this step may take a while on a CPU.\n","Also, the default learning rate is not optimal for all of the models, so\n","to achieve maximum accuracy it would be necessary to tune for each model\n","separately.\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"zefDvXANyH3v","colab_type":"code","outputId":"8a0dcf99-ca02-464b-a78f-6952338b606d","executionInfo":{"status":"error","timestamp":1578959126058,"user_tz":-60,"elapsed":836150,"user":{"displayName":"Jaime Simarro","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAaCDZo0qY0_I_MWZkHYpC_qNonaZr8W0nMUic4Aw=s64","userId":"03169857515179805755"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["from MAIA_model import train_complete_model\n","\n","# Setup the loss fxn\n","criterion = nn.CrossEntropyLoss()\n","\n","if not os.path.isdir(options[\"models_dir\"]):\n","        print(\"Creating Experiment Folder\")\n","        os.mkdir(options[\"models_dir\"])\n","\n","save_model_path= os.path.join(options['models_dir'], SUB_EXPERIMENT_NAME )\n","\n","# Train the model\n","try:\n","  training_metrics = train_complete_model(device, model_ft,  dataloader_complete_train, criterion, optimizer_ft, num_epochs=NUM_EPOCHS,save_model_path=save_model_path,is_inception=(MODEL_NAME==\"inception\"))\n","except KeyboardInterrupt:\n","    pass\n","\n","# Save results\n","df_training = pd.DataFrame(training_metrics, columns=[\"train_loss\",\"train_acc\",\"val_loss\",\" val_acc\"],index=list(range(1,NUM_EPOCHS+1)))\n","df_training.to_excel(options[\"models_dir\"]+'/'+MODEL_NAME+\".xlsx\")\n","df_training.describe().T"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch 1/16\n","----------\n","29494/29494: [===============================>] - ETA 0.2s\n","Loss: 0.3116 Acc: 0.8691\n","\n","Epoch 2/16\n","----------\n","29494/29494: [===============================>] - ETA 0.2s\n","Loss: 0.2262 Acc: 0.9111\n","\n","Epoch 3/16\n","----------\n","29494/29494: [===============================>] - ETA 0.2s\n","Loss: 0.1998 Acc: 0.9241\n","\n","Epoch 4/16\n","----------\n","29494/29494: [===============================>] - ETA 0.2s\n","Loss: 0.1810 Acc: 0.9294\n","\n","Epoch 5/16\n","----------\n","29494/29494: [===============================>] - ETA 0.2s\n","Loss: 0.1730 Acc: 0.9350\n","\n","Epoch 6/16\n","----------\n","29494/29494: [===============================>] - ETA 0.2s\n","Loss: 0.1664 Acc: 0.9389\n","\n","Epoch 7/16\n","----------\n","29494/29494: [===============================>] - ETA 0.2s\n","Loss: 0.1551 Acc: 0.9400\n","\n","Epoch 8/16\n","----------\n","29494/29494: [===============================>] - ETA 0.2s\n","Loss: 0.1444 Acc: 0.9461\n","\n","Epoch 9/16\n","----------\n","29494/29494: [===============================>] - ETA 0.2s\n","Loss: 0.1417 Acc: 0.9472\n","\n","Epoch 10/16\n","----------\n","29494/29494: [===============================>] - ETA 0.2s\n","Loss: 0.1338 Acc: 0.9499\n","\n","Epoch 11/16\n","----------\n","29494/29494: [===============================>] - ETA 0.2s\n","Loss: 0.1251 Acc: 0.9527\n","\n","Epoch 12/16\n","----------\n","29494/29494: [===============================>] - ETA 0.2s\n","Loss: 0.1252 Acc: 0.9531\n","\n","Epoch 13/16\n","----------\n","29494/29494: [===============================>] - ETA 0.2s\n","Loss: 0.1220 Acc: 0.9551\n","\n","Epoch 14/16\n","----------\n","29494/29494: [===============================>] - ETA 0.2s\n","Loss: 0.1125 Acc: 0.9590\n","\n","Epoch 15/16\n","----------\n","10208/29494: [===========>....................] - ETA 124.9s"],"name":"stdout"},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mcreate_block_manager_from_blocks\u001b[0;34m(blocks, axes)\u001b[0m\n\u001b[1;32m   1680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1681\u001b[0;31m         \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBlockManager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1682\u001b[0m         \u001b[0mmgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, blocks, axes, do_integrity_check)\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdo_integrity_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_verify_integrity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m_verify_integrity\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_verify_integrity\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mmgr_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m                 \u001b[0mconstruction_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtot_items\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtot_items\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mconstruction_error\u001b[0;34m(tot_items, block_shape, axes, e)\u001b[0m\n\u001b[1;32m   1718\u001b[0m     raise ValueError(\n\u001b[0;32m-> 1719\u001b[0;31m         \u001b[0;34m\"Shape of passed values is {0}, indices imply {1}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpassed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimplied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1720\u001b[0m     )\n","\u001b[0;31mValueError\u001b[0m: Shape of passed values is (20, 4), indices imply (16, 4)","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-42-3e48fde2cd94>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Save results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mdf_training\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_metrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train_loss\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"train_acc\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"val_loss\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\" val_acc\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mNUM_EPOCHS\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mdf_training\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"models_dir\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mMODEL_NAME\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".xlsx\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mdf_training\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    438\u001b[0m                 \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m                 \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_ndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m         \u001b[0;31m# For data is list-like, or Iterable (will consume into list)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36minit_ndarray\u001b[0;34m(values, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0mblock_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcreate_block_manager_from_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mcreate_block_manager_from_blocks\u001b[0;34m(blocks, axes)\u001b[0m\n\u001b[1;32m   1686\u001b[0m         \u001b[0mblocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"values\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m         \u001b[0mtot_items\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1688\u001b[0;31m         \u001b[0mconstruction_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtot_items\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mconstruction_error\u001b[0;34m(tot_items, block_shape, axes, e)\u001b[0m\n\u001b[1;32m   1717\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Empty data passed with indices specified.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1718\u001b[0m     raise ValueError(\n\u001b[0;32m-> 1719\u001b[0;31m         \u001b[0;34m\"Shape of passed values is {0}, indices imply {1}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpassed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimplied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1720\u001b[0m     )\n\u001b[1;32m   1721\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Shape of passed values is (20, 4), indices imply (16, 4)"]}]}]}